# Numerical-Optimization-Methods-with-Julia

This repository contains a collection of Jupyter Notebooks implementing and analyzing numerical optimization methods. These methods are implemented using the **Julia programming language**, known for its performance and efficiency in numerical and scientific computing. The repository provides a practical and theoretical foundation for solving both unconstrained and constrained optimization problems.

## Notebooks Overview

1. **`armijo.ipynb`**:
   - Demonstrates the implementation of the Armijo rule for step-size selection in optimization algorithms.
   - Aims to enhance convergence while ensuring numerical stability.

2. **`conjugate_gradient_method.ipynb`**:
   - Implements the Conjugate Gradient Method.
   - Useful for solving large-scale optimization problems and systems of linear equations.
   - Includes insights into the method's efficiency and convergence behavior.

3. **`gradient_descent_method.ipynb`**:
   - Implements the Gradient Descent Method.
   - A foundational optimization algorithm for minimizing differentiable functions.
   - Includes step-size strategies and visualization of convergence.

4. **`kkt.ipynb`**:
   - Explores the Karush–Kuhn–Tucker (KKT) conditions.
   - Focuses on solving constrained optimization problems.
   - Includes examples and sensitivity analysis for the method.

5. **`wolfe_method.ipynb`**:
   - Explores Wolfe conditions for line search in optimization.
   - Ensures sufficient decrease and curvature conditions in step-size selection.
   - Provides practical examples and visualizations.
