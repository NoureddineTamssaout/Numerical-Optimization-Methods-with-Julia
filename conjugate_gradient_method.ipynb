{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7614fd3-c9c4-450a-a9bf-3dcd21ba42be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimisation de f1\n",
      "Point initial : [0.0, 0.0] -> Résultat : x* = [1.108697762387319e11, 1.108697762387319e11], f(x*) = 7.375264369802845e22, itérations : 4, Convergence : true\n",
      "Point initial : [1.0, 1.0] -> Résultat : x* = [-4.716329462351166e16, -4.716329462351166e16], f(x*) = 1.3346258158464986e34, itérations : 5, Convergence : true\n",
      "Point initial : [-1.0, -1.0] -> Résultat : x* = [2.2173947829160565e11, 2.2173947829160565e11], f(x*) = 2.9501037739553984e23, itérations : 4, Convergence : true\n",
      "Point initial : [2.0, 2.0] -> Résultat : x* = [-1.1086962824393764e11, -1.1086962824393764e11], f(x*) = 7.375244680302403e22, itérations : 4, Convergence : true\n",
      "Point initial : [0.5, -0.5] -> Résultat : x* = [1.663508583430585e12, 1.249633693589455e13], f(x*) = 5.941272629815111e26, itérations : 4, Convergence : true\n",
      "\n",
      "Minimisation de f2\n",
      "Point initial : [0.0, 0.0] -> Résultat : x* = [5.295357142443002, -2.207277873367275], f(x*) = 4.7958318641516644e-12, itérations : 1, Convergence : true\n",
      "Point initial : [1.0, 1.0] -> Résultat : x* = [-31.893755833799748, -9.78617271773088], f(x*) = 0.0, itérations : 4, Convergence : true\n",
      "Point initial : [-1.0, -1.0] -> Résultat : x* = [15.167867097692652, 332.64539296805515], f(x*) = 0.0, itérations : 5, Convergence : true\n",
      "Point initial : [2.0, 2.0] -> Résultat : x* = [3.3407271455253817, 2.8072757574223473], f(x*) = 2.023881863136058e-5, itérations : 1000, Convergence : false\n",
      "Point initial : [0.5, -0.5] -> Résultat : x* = [59.88222387305223, 31.690611686217107], f(x*) = 0.0, itérations : 5, Convergence : true\n"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra  # Nécessaire pour norm\n",
    "\n",
    "# Paramètres globaux\n",
    "eps_tolerance = 1e-6   # Tolérance pour le critère d'arrêt\n",
    "max_iterations = 1000  # Nombre maximum d'itérations\n",
    "\n",
    "# Gradient approximé\n",
    "function grad_f(f, x::Vector{Float64})\n",
    "    grad = zeros(Float64, length(x))\n",
    "    for i in 1:length(x)\n",
    "        x_plus = copy(x)\n",
    "        x_plus[i] += eps_tolerance\n",
    "        grad[i] = (f(x_plus) - f(x)) / eps_tolerance\n",
    "    end\n",
    "    return grad\n",
    "end\n",
    "\n",
    "# Méthode du gradient conjugué\n",
    "function conjugate_gradient(f, x0::Vector{Float64})\n",
    "    xk = x0\n",
    "    gk = grad_f(f, xk)\n",
    "    dk = -gk\n",
    "    iters = 0\n",
    "\n",
    "    while norm(gk) > eps_tolerance && iters < max_iterations\n",
    "        # Calcul du pas optimal par recherche linéaire simplifiée\n",
    "        αk = 1.0\n",
    "        xk_next = xk + αk * dk\n",
    "\n",
    "        # Mise à jour du gradient\n",
    "        gk_next = grad_f(f, xk_next)\n",
    "\n",
    "        # Calcul du coefficient bêta (Polak-Ribière)\n",
    "        beta_k = dot(gk_next, gk_next - gk) / dot(gk, gk)\n",
    "\n",
    "        # Mise à jour de la direction conjuguée\n",
    "        dk = -gk_next + beta_k * dk\n",
    "\n",
    "        # Préparation pour la prochaine itération\n",
    "        xk, gk = xk_next, gk_next\n",
    "        iters += 1\n",
    "    end\n",
    "\n",
    "    converged = norm(gk) <= eps_tolerance\n",
    "    return (xk, f(xk), iters, converged)\n",
    "end\n",
    "\n",
    "# Fonctions à minimiser\n",
    "function f1(x::Vector{Float64})\n",
    "    x1, x2 = x\n",
    "    return 4 * (x1^2 + x2^2) - 2 * x1 * x2 - 6 * (x1 + x2)\n",
    "end\n",
    "\n",
    "function f2(x::Vector{Float64})\n",
    "    x1, x2 = x\n",
    "    return 3 * (1 - x1)^2 * exp(-x1^2 - (x2 - 1)^2) -\n",
    "           10 * (x1 / 3 - x1^3 - x2^5) * exp(-x1^2 - x2^2) -\n",
    "           (1 / 3) * exp(-(x1 + 1)^2 - x2^2)\n",
    "end\n",
    "\n",
    "# Fonction de test\n",
    "function test_conjugate_gradient()\n",
    "    points = [[0.0, 0.0], [1.0, 1.0], [-1.0, -1.0], [2.0, 2.0], [0.5, -0.5]]\n",
    "    \n",
    "    println(\"Minimisation de f1\")\n",
    "    for p in points\n",
    "        result = conjugate_gradient(f1, p)\n",
    "        println(\"Point initial : $p -> Résultat : x* = $(result[1]), f(x*) = $(result[2]), itérations : $(result[3]), Convergence : $(result[4])\")\n",
    "    end\n",
    "\n",
    "    println(\"\\nMinimisation de f2\")\n",
    "    for p in points\n",
    "        result = conjugate_gradient(f2, p)\n",
    "        println(\"Point initial : $p -> Résultat : x* = $(result[1]), f(x*) = $(result[2]), itérations : $(result[3]), Convergence : $(result[4])\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# Test\n",
    "test_conjugate_gradient()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
